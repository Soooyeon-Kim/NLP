{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c27037",
   "metadata": {},
   "source": [
    "# 2.2 Sklearn\n",
    "* 데이터 불러오기\n",
    "* 2.2.1. 싸이킷-런 데이터 분리\n",
    "* 2.2.2. 싸이킷-런 지도 학습\n",
    "* 2.2.3. 싸이킷-런 비지도 학습\n",
    "* 2.2.4. 싸이킷-런 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d939a8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935bb4b4",
   "metadata": {},
   "source": [
    "### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8819c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84bc1839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_dataset key: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = load_iris()\n",
    "print(\"iris_dataset key: {}\".format(iris_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fda281a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "shape of data: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['data'])\n",
    "print(\"shape of data: {}\". format(iris_dataset['data'].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f329f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbfc7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['target'])\n",
    "print(iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b85112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea1829",
   "metadata": {},
   "source": [
    "'DESCR'은 'Description'의 약자로서 해당 데이터에 대한 전체적인 요약 정보를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b559ae3",
   "metadata": {},
   "source": [
    "## 2.2.1. 싸이킷-런 데이터 분리\n",
    "사이킷런을 이용하면 학습 데이터를 대상으로 학습 데이터와 평가 데이터로 쉽게 나눌 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "493d25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2e7318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_label, test_label = train_test_split(iris_dataset['data'],\n",
    "                                                                    iris_dataset['target'],\n",
    "                                                                    test_size = 0.25,\n",
    "                                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b760b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_input: (112, 4)\n",
      "shape of test_input: (38, 4)\n",
      "shape of train_label: (112,)\n",
      "shape of test_label: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train_input: {}\".format(train_input.shape))\n",
    "print(\"shape of test_input: {}\".format(test_input.shape))\n",
    "print(\"shape of train_label: {}\".format(train_label.shape))\n",
    "print(\"shape of test_label: {}\".format(test_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b6ca7",
   "metadata": {},
   "source": [
    "## 2.2.2. 싸이킷-런 지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bffed0c",
   "metadata": {},
   "source": [
    "* 지도학습 : 각 데이터에 대해 정답이 있는 경우 각 데이터의 정답을 예측할 수 있게 학습시키는 과정 -> 즉 모델이 예측하는 결과를 각 데이터의 정답과 비교해서 모델을 반복적으로 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4c109d",
   "metadata": {},
   "source": [
    "### k-최근접 이웃 분류기 (K-nearest neighbor classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee101a7a",
   "metadata": {},
   "source": [
    "예측하고자 하는 데이터에 대해 가장 가까운 거리에 있는 데이터의 라벨과 같다고 예측하는 방법\n",
    "\n",
    "이 방법은 데이터에 대한 사전 지식이 없는 경우의 분류에 많이 사용된다\n",
    "k 값은 예측하고자 하는 데이터와 가까운 몇 개의 데이터를 참고할 것인지를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb4a9d",
   "metadata": {},
   "source": [
    "#### k-최근접 이웃 분류기의 특징\n",
    "* 데이터에 대한 가정이 없어 단순하다.\n",
    "* 다목적 분류와 회귀에 좋다.\n",
    "* 높은 메모리를 요구한다.\n",
    "* k값이 커지면 계산이 늦어질 수 있다.\n",
    "* 관련 없는 기능의 데이터 규모에 민감하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a80f12a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 객체를 불러온 뒤 객체에 할당\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "436c38bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a6873af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4개의 피처값을 임의로 설정해서 넘파이 배열로 만든다\n",
    "import numpy as np\n",
    "new_input = np.array([[6.1, 2.8, 4.7, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "887d75b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 예측\n",
    "knn.predict(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03fc0690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "# 따로 분리해둔 평가 데이터에 대해 예측하고 그 결과값을 변수에 저장한다\n",
    "predict_label = knn.predict(test_input)\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15d1078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 1.00\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값과 실제 결과값을 비교해서 정확도 측정\n",
    "print('test accuracy {:.2f}'.format(np.mean(predict_label == test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357edf9",
   "metadata": {},
   "source": [
    "## 2.2.3. 싸이킷-런 비지도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0262e",
   "metadata": {},
   "source": [
    "* 비지도 학습 : 지도 학습과는 달리 데이터에 대한 정답, \n",
    "   *  -> 즉 라벨을 사용하지 않고 만들 수 있는 모델\n",
    "   * 모델을 통해 문제를 해결하면서 데이터에 대한 정답이 없는 경우 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f94a0b",
   "metadata": {},
   "source": [
    "#### k-평균 군집화 (K-means Clustering)\n",
    "* 군집화란 데이터를 특성에 따라 여러 집단으로 나누는 방법\n",
    "* k-평균 군집화는 군집화 방법 중 가장 간단하고 널리 사용되는 방법\n",
    "* 데이터 안에서 대표하는 군집의 중심을 찾는 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cba791b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "248833d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c33eab",
   "metadata": {},
   "source": [
    "라벨값을 넣지 않고 단순히 데이터 사이의 거리를 이용하여 군집화한 것이기 때문에 바로 붓꽃의 라벨을 예측할 수 없지만 군집화한 k-평균 군집화 모델의 라벨 속성을 확인하면 각 데이터의 라벨을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ffbcdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 2, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 2, 1,\n",
       "       1, 0, 2, 1, 0, 1, 1, 0, 0, 2, 0, 2, 2, 0, 1, 1, 0, 2, 1, 1, 1, 0,\n",
       "       2, 1, 2, 2, 1, 0, 0, 0, 2, 2, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       2, 2, 1, 0, 2, 2, 1, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70f99458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cluster: [2 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 1 2 1]\n",
      "1 cluster: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "2 cluster: [2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# 각 군집의 종 확인\n",
    "print(\"0 cluster:\", train_label[k_means.labels_ == 0])\n",
    "print(\"1 cluster:\", train_label[k_means.labels_ == 1])\n",
    "print(\"2 cluster:\", train_label[k_means.labels_ == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9f8e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 새로운 데이터를 만들어서 예측을 진행\n",
    "import numpy as np\n",
    "new_input  = np.array([[6.1, 2.8, 4.7, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6587457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "prediction = k_means.predict(new_input)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df03eb6",
   "metadata": {},
   "source": [
    "결과 : 새롭게 정의된 데이터는 0군집에 포함된다고 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "347ad627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 0 0 1 0 2 0 0 2 1 1 1 1 0 2 0 0 2 1 0 1 2 2 2 2 2 1 1 1 1 0 1 1 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# 평가데이터를 적용시켜 실제 라벨과 비교해 성능을 측정한다\n",
    "predict_cluster = k_means.predict(test_input)\n",
    "print(predict_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e93d9fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "#  적용시켜 예측한 군집을 각 붓꽃의 종을 의미하는 라벨값으로 다시 바꿔줘야 실제 라벨과 비교해서 성능을 측정할 수 있음\n",
    "np_arr = np.array(predict_cluster)\n",
    "np_arr[np_arr==0], np_arr[np_arr==1], np_arr[np_arr==2] = 3, 4, 5\n",
    "np_arr[np_arr==3] = 1\n",
    "np_arr[np_arr==4] = 0\n",
    "np_arr[np_arr==5] = 2\n",
    "predict_label = np_arr.tolist()\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62401b3a",
   "metadata": {},
   "source": [
    "각 데이터가 속한 군집의 순서를 실제 붓꽃의 라벨로 변경\n",
    "* 0번째 군집이 라벨 1 (Versicolour)\n",
    "* 1번째 군집이 라벨 0 (Setosa)\n",
    "* 2번째 군집이 라벨 2 (Verginica)\n",
    "\n",
    "* -> 변경할 때는 임시저장을 위해 군집의 순서값 3,4,5 를 넘파이 배열로 먼저 만들고 군집 3을 1(Versicolour), 군집 4: 0 (Setosa), 군집 5: 2 (Verginica)로 바꿔준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e4a405e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.95\n"
     ]
    }
   ],
   "source": [
    "#실제 라벨과 비교하여 성능 확인\n",
    "print('test accuracy {:.2f}'.format(np.mean(predict_label == test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c4b365",
   "metadata": {},
   "source": [
    "## 2.2.4. 싸이킷-런 특징 추출\n",
    "자연어 처리에서 특징 추출이란 텍스트 데이터에서 단어나 문장들을 어떤 특징 값으로 바꿔주는 것을 의미한다. 기존에 문자로 구성되어 있던 데이터를 모델에 적용할 수 있도록 특징을 뽑아 어떤 값으로 바꿔서 수치화한다. \n",
    "* CountVectorizer\n",
    "* TfidfVectorizer\n",
    "* HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd7e35",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c7691e",
   "metadata": {},
   "source": [
    "* 단순히 각 텍스트에서 횟수를 기준으로 특징을 추출하는 방법\n",
    "* 어떤 단위의 횟수를 셀 것인지는 선택 사항[단어, 문자 하나하나]\n",
    "1. 문장을 입력받아 단어의 횟수를 측정한 뒤 벡터로 만든다\n",
    "2. 객체를 만들고 특정 텍스트를 적합( = 횟수를 셀 단어의 목록을 만드는 과정) \n",
    "3. 횟수를 기준으로 해당 텍스트를 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "085de845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec0b0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29be6312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "# 생성한 객체에 fit 함수를 사용해 데이터를 적용 -> 자동으로 단어사전 생성\n",
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "249ecb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 실제로 벡터화\n",
    "sentence = [text_data[0]] # ['나는 배가 고프다']\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79cf9f2",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "* TF - IDF 라는 특정한 값을 사용해서 텍스트 데이터의 특징을 추출하는 방법\n",
    "* TF  [Term Frequency] : 특정 단어가 하나의 데이터 안에서 등장하는 횟수를 의미한다.\n",
    "* DF [Document Frequency] : 문서 빈도 값으로, 특정 단어가 여러 데이터에 자주 등장하는 지를 알려주는 지표\n",
    "* IDF [Inverse Document Frequency] : 이 값에 역수를 취해 구할 수 있으며, 특정 단어가 다른 데이터에 등장하지 않을 수록 값이 커진다는 것을 의미한다\n",
    "#### \n",
    "* TF - IDF 란 이 두 값을 곱해서 사용하므로 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어일수록 높은 값을 가지게 된다\n",
    "-> 따라서 조사나 지시대명사처럼 자주 등장하는 단어는 TF 값은 크지만 IDF 값은 작아지므로 TfidfVectorizer는 CountVectorizer가 가진 문제점을 해결할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7b5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfdc2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e586ff",
   "metadata": {},
   "source": [
    "단어사전을 만든 후 단어사전의 목록을 출력하고, 해당 데이터의 한 문장만 객체에 적용해 벡터로 바뀐 값을 출력한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b30ba83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
      "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "sentence = [text_data[3]] # ['점심 먹고 공부 해야지']\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
