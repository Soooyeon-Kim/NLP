{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7d5206",
   "metadata": {},
   "source": [
    "## 3 어간 추출(Stemming) and 표제어 추출(Lemmatization)\n",
    "\n",
    "### 1. 표제어 추출(Lemmatization)\n",
    "* 표제어(Lemma): 한글로 '표제어' 또는 '기본 사전형 단어'\n",
    "* 표제어 추출: 단어들로부터 표제어를 찾아가는 과정\n",
    "* 표제어 추출을 하는 가장 섬세한 방법은 단어의 형태학적 파싱을 먼저 진행하는 것\n",
    "\n",
    "#### 형태소\n",
    "* 형태소: '의미를 가진 가장 작은 단위'\n",
    "* 형태학(morphology): 형태소로부터 단어들을 만들어가는 학문\n",
    "\n",
    "#### 형태소의 두 가지 종류\n",
    "1) 어간(stem)\n",
    ": 단어의 의미를 담고 있는 단어의 핵심 부분.\n",
    "\n",
    "2) 접사(affix)\n",
    ": 단어에 추가적인 의미를 주는 부분.\n",
    "\n",
    "-> 형태학적 파싱은 이 두 가지 구성 요소를 분리하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31073db9",
   "metadata": {},
   "source": [
    "#### NLTK 표제어 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8db1d0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "n=WordNetLemmatizer()\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print([n.lemmatize(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48a0c2",
   "metadata": {},
   "source": [
    " dies와 has가 dy, ha로  의미를 알 수 없는 적절하지 못한 단어를 출력됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569c15e",
   "metadata": {},
   "source": [
    "#### 표제어 추출기(lemmatizer)는 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있음\n",
    "#### 이때, WordNetLemmatizer는 입력으로 단어가 동사 품사라는 사실을 알려줄 수 있음\n",
    " dies와 watched, has가 문장에서 동사로 쓰였다는 것을 알려준다면 표제어 추출기는 품사의 정보를 보존하면서 정확한 Lemma를 출력함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47d8d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('dies', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9749df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('watched', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9892e095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.lemmatize('has', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3471f74",
   "metadata": {},
   "source": [
    "### 2. 어간 추출(Stemming)\n",
    "* 어간 추출은 형태학적 분석을 단순화한 버전\n",
    "* 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업\n",
    "* 어간 추출 속도는 표제어 추출보다 일반적으로 빠름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1f08cd",
   "metadata": {},
   "source": [
    "#### NLTK 포터 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17aee6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "s = PorterStemmer()\n",
    "text=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "words=word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78fa53f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e0d2a",
   "metadata": {},
   "source": [
    "#### 포터 알고리즘의 어간 추출 규칙\n",
    "* ALIZE → AL\n",
    "* ANCE → 제거\n",
    "* ICAL → IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f5e71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "words=['formalize', 'allowance', 'electricical']\n",
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60634fdf",
   "metadata": {},
   "source": [
    "#### NLTK 랭커스터 스태머(Lancaster Stemmer) 알고리즘 (vs 포터 알고리즘 비교)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "185342fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "s=PorterStemmer()\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print([s.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "211f1e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "l=LancasterStemmer()\n",
    "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "print([l.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a94e65",
   "metadata": {},
   "source": [
    "표제어 추출과 어간 추출을 각각 수행했을 때, 결과 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c1d97",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "* am → am\n",
    "* the going → the go\n",
    "* having → hav\n",
    "\n",
    "#### Lemmatization\n",
    "* am → be\n",
    "* the going → the going\n",
    "* having → have"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
