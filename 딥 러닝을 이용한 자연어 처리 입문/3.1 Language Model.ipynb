{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3daac935",
   "metadata": {},
   "source": [
    "## 03. 언어 모델(Language Model)\n",
    "언어 모델(Languagel Model)이란 단어 시퀀스(문장)에 확률을 할당하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66146bf",
   "metadata": {},
   "source": [
    "### SLM\n",
    "* 통계에 기반한 전통적인 언어 모델(Statistical Languagel Model, SLM)\n",
    "* 통계 기반 방법론에 대한 이해는 언어 모델에 대한 전체적인 시야를 갖는 일에 도움\n",
    "#### n-gram\n",
    "통계 기반 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf3187",
   "metadata": {},
   "source": [
    "## 1) 언어 모델(Language Model)이란?\n",
    "언어 모델(Language Model, LM)은 언어라는 현상을 모델링하고자 단어 시퀀스(또는 문장)에 확률을 할당(assign)하는 모델, 즉 언어 모델은 가장 자연스러운 단어 시퀀스를 찾아내는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8075307",
   "metadata": {},
   "source": [
    "#### 언어 모델을 만드는 방법\n",
    "* 통계를 이용한 방법\n",
    "* 인공 신경망을 이용한 방법\n",
    "     \n",
    "     \n",
    "최근에는 통계를 이용한 방법보다는 인공 신경망을 이용한 방법이 더 좋은 성능을 보여주고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34515e7c",
   "metadata": {},
   "source": [
    "## 1. 언어 모델(Language Model)\n",
    "언어 모델로 단어나 문장 시퀀스에 확률을 할당하게 하기 위해서 가장 보편적으로 사용되는 방법은 언어 모델이 이전 단어들이 주어졌을 때 다음 단어를 예측하도록 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb3667",
   "metadata": {},
   "source": [
    "### 언어 모델링(Language Modeling) \n",
    "주어진 단어들로부터 아직 모르는 단어를 예측하는 작업을 말합니다. 즉, 언어 모델이 이전 단어들로부터 다음 단어를 예측하는 일은 언어 모델링입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2149a7",
   "metadata": {},
   "source": [
    "## 2. 단어 시퀀스의 확률 할당\n",
    "자연어 처리에서 단어 시퀀스에 확률을 할당하는 일이 필요한 이유 :\n",
    "#### 언어 모델은 아래와 같이 확률을 통해 보다 적절한 문장을 판단하기 때문에"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d088c",
   "metadata": {},
   "source": [
    "### a. 기계 번역(Machine Translation):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09139d9a",
   "metadata": {},
   "source": [
    "#### P(나는 버스를 탔다) > P(나는 버스를 태운다)\n",
    ": 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7afea9e",
   "metadata": {},
   "source": [
    "### b. 오타 교정(Spell Correction)\n",
    "선생님이 교실로 부리나케\n",
    "#### P(달려갔다) > P(잘려갔다)\n",
    ": 언어 모델은 두 문장을 비교하여 좌측의 문장의 확률이 더 높다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a3d823",
   "metadata": {},
   "source": [
    "### c. 음성 인식(Speech Recognition)\n",
    "나는 \n",
    "#### P(메롱을 먹는다) < P(나는 메론을 먹는다)\n",
    ": 언어 모델은 두 문장을 비교하여 우측의 문장의 확률이 더 높다고 판단함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837dfe8d",
   "metadata": {},
   "source": [
    "## 3. 주어진 이전 단어들로부터 다음 단어 예측하기\n",
    "언어 모델은 단어 시퀀스에 확률을 할당하는 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be999906",
   "metadata": {},
   "source": [
    "* 단어 시퀀스에 확률을 할당하기 위해서 가장 보편적으로 사용하는 방법 :  \n",
    "전 단어들이 주어졌을 때, 다음 단어를 예측하도록 하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec76c54",
   "metadata": {},
   "source": [
    "### A. 단어 시퀀스의 확률\n",
    "* 하나의 단어를 'w', 단어 시퀀스을 대문자 'W'라고 한다면, \n",
    "n개의 단어가 등장하는 단어 시퀀스 W의 확률은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f1307",
   "metadata": {},
   "source": [
    "P(W) = P(w_1, w_2, w_3, w_4, w_5, ... ,w_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80badaf0",
   "metadata": {},
   "source": [
    "### B. 다음 단어 등장 확률\n",
    "단어 등장 확률을 식으로 표현 \n",
    "* n-1개의 단어가 나열된 상태에서 n번째 단어의 확률\n",
    "* |의 기호는 조건부 확률(conditional probability)을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da309a3",
   "metadata": {},
   "source": [
    "P(w_n | w_1, ..., w_{n-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f422a29",
   "metadata": {},
   "source": [
    "#### ex) 다섯번째 단어의 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc2d0fc",
   "metadata": {},
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mi>P</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>5</mn>\n",
    "  </msub>\n",
    "  <mo data-mjx-texclass=\"ORD\" stretchy=\"false\">|</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>3</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>4</mn>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e9dc57",
   "metadata": {},
   "source": [
    "** 전체 단어 시퀀스 W의 확률은 모든 단어가 예측되고 나서야 알 수 있으므로 단어 시퀀스의 확률은 다음과 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce34fc4",
   "metadata": {},
   "source": [
    "<math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\">\n",
    "  <mi>P</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <mi>W</mi>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <mi>P</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>1</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>2</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>3</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>4</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mn>5</mn>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>.</mo>\n",
    "  <mo>.</mo>\n",
    "  <mo>.</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mi>n</mi>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "  <mo>=</mo>\n",
    "  <munderover>\n",
    "    <mo data-mjx-texclass=\"OP\">&#x220F;</mo>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mi>i</mi>\n",
    "      <mo>=</mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mi>n</mi>\n",
    "    </mrow>\n",
    "  </munderover>\n",
    "  <mi>P</mi>\n",
    "  <mo stretchy=\"false\">(</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mi>n</mi>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo data-mjx-texclass=\"ORD\" stretchy=\"false\">|</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo>,</mo>\n",
    "  <mo>.</mo>\n",
    "  <mo>.</mo>\n",
    "  <mo>.</mo>\n",
    "  <mo>,</mo>\n",
    "  <msub>\n",
    "    <mi>w</mi>\n",
    "    <mrow data-mjx-texclass=\"ORD\">\n",
    "      <mi>n</mi>\n",
    "      <mo>&#x2212;</mo>\n",
    "      <mn>1</mn>\n",
    "    </mrow>\n",
    "  </msub>\n",
    "  <mo stretchy=\"false\">)</mo>\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3aa16",
   "metadata": {},
   "source": [
    "## 4. 언어 모델의 간단한 직관"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266b0ea",
   "metadata": {},
   "source": [
    "기계가 최대한 정확히 다음에 나올 단어를 예측할 수 있는 방법은 앞에 어떤 단어들이 나왔는지 고려하여 후보가 될 수 있는 여러 단어들에 대해서 등장 확률을 추정하고 가장 높은 확률을 가진 단어를 선택하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef262d",
   "metadata": {},
   "source": [
    "## 5. 검색 엔진에서의 언어 모델의 예\n",
    "검색 엔진이 입력된 단어들의 나열에 대해서 다음 단어를 예측하는 언어 모델을 사용하고 있습니다.\n",
    "(연관검색어 도출)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
