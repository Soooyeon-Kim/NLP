{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0067f52e",
   "metadata": {},
   "source": [
    "## 5) 펄플렉서티(Perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd09e50",
   "metadata": {},
   "source": [
    "#### 두 개의 모델 A, B의 성능을 비교하는 방법\n",
    "두 개의 모델을 오타 교정, 기계 번역 등의 평가에 투입해보거나. 두 모델이 해당 업무의 성능을 누가 더 잘했는지를 비교한다면 이를 외부 평가라 한다.\n",
    "\n",
    " **외부 평가(extrinsic evaluation)** \n",
    "* 두 모델의 성능을 비교하고자, 일일히 모델들에 대해서 실제 작업을 시켜보고 정확도를 비교하는 작업 -> 공수가 너무 많이 드는 작업\n",
    "* 만약 비교해야하는 모델이 두 개가 아니라 그 이상의 수라면 시간은 비교해야하는 모델의 수만큼 배로 늘어날 수도 있음\n",
    "\n",
    "**내부 평가(Intrinsic evaluation)**\n",
    "* 외부 평가보다 어쩌면 조금은 부정확할 수는 있어도 테스트 데이터에 대해서 빠르게 식으로 계산되는 더 간단한 평가 방법 \n",
    "* 모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 내부평가로서 **펄플렉서티(perplexity)** 가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066adb8",
   "metadata": {},
   "source": [
    "### 1. 언어 모델의 평가 방법(Evaluation metric) : PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77738b59",
   "metadata": {},
   "source": [
    "펄플렉서티(perplexity)는 언어 모델을 평가하기 위한 내부 평가 지표이며, 보통 줄여서 PPL이 라고 표현함\n",
    "\n",
    "* 영어에서 'perplexed'는 '헷갈리는'과 유사한 의미를 가짐.\n",
    "* => PPL은 '헷갈리는 정도' \n",
    "* PPL은 수치가 높으면 좋은 성능을 의미하는 것이 아니라, **낮을수록** 언어 모델의 성능이 좋다는 것을 의미함\n",
    "\n",
    "* PPL은 단어의 수로 정규화(normalization) 된 테스트 데이터에 대한 확률의 역수\n",
    "* PPL을 최소화한다는 것은 문장의 확률을 최대화하는 것과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7228635",
   "metadata": {},
   "source": [
    "### 2. 분기 계수(Branching factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0faf1e6",
   "metadata": {},
   "source": [
    "PPL은 선택할 수 있는 가능한 경우의 수를 의미하는 **분기계수(branching factor)** 이며\n",
    "\n",
    "PPL은 이 언어 모델이 특정 시점에서 평균적으로 몇 개의 **선택지**를 가지고 고민하고 있는지를 의미함. \n",
    "\n",
    "\n",
    "ex) \n",
    "언어 모델에 어떤 테스트 데이터을 주고 측정했을 때의 PPL이 10이라면,\n",
    "해당 언어 모델은 테스트 데이터에 대해서 다음 단어를 예측하는 모든 시점(time-step)마다 평균적으로 10개의 단어를 가지고 어떤 것이 정답인지 고민하고 있다고 볼 수 있다. \n",
    "\n",
    "* 같은 테스트 데이터에 대해서 두 언어 모델의 PPL을 각각 계산 후에 PPL의 값을 비교하면, 두 언어 모델 중 어떤 것이 성능이 좋은지도 판단이 가능. \n",
    "#### => PPL이 더 낮은 언어 모델의 성능이 더 좋다고 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79272e04",
   "metadata": {},
   "source": [
    "#### 평가 방법에 있어서 주의할 점 \n",
    "* PPL의 값이 낮다는 것은 테스트 데이터 상에서 높은 정확도를 보인다는 것이지, 사람이 직접 느끼기에 반드시 좋은 언어 모델이라는 것을 의미하진 않는다.\n",
    "* 또한 언어 모델의 PPL은 **테스트 데이터에 의존**하므로 두 개 이상의 언어 모델을 비교할 때는 정량적으로 양이 많고, 또한 도메인에 알맞은 동일한 테스트 데이터를 사용해야 신뢰도가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31892c",
   "metadata": {},
   "source": [
    "### 3. 기존 언어 모델 VS 인공 신경망을 이용한 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9ef26",
   "metadata": {},
   "source": [
    "https://wikidocs.net/images/page/21697/ppl.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d29915",
   "metadata": {},
   "source": [
    "n-gram 언어 모델과 딥 러닝을 이용한 언어 모델에 대해서 PPL로 성능 테스트를 한 표를 참고하여 PPL의 실제 사용 사례를 확인해보면,\n",
    "인공 신경망을 이용한 언어 모델들은 대부분 n-gram을 이용한 언어 모델보다 더 좋은 성능 평가를 받았음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d01076",
   "metadata": {},
   "source": [
    "링크 : https://research.fb.com/building-an-efficient-neural-language-model-over-a-billion-words/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
